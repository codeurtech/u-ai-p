# Spring AI Chat Endpoint - Gemma 3-4b

## Overview

This project exposes a REST API endpoint (`/chat`) that leverages Spring Boot and LM Studio to provide chatbot functionality powered by Google Gemma 3-4b.  Users can submit text prompts through the API and receive responses generated by the Gemma model running within LM Studio.

## Technologies Used

*   **Spring Boot:** For building the REST API application in Java/Kotlin.
*   **LM Studio:** Used as a local environment for running Google Gemma 3-4b and managing the model.
*   **Google Gemma 3-4b:** The Large Language Model powering the chatbot responses.
*   **Java/Kotlin (Spring Boot):** The backend programming language and framework.

## Endpoint: `/chat`

*   **Method:** `POST`
*   **Request Body (JSON):**  Accepts a JSON payload with the following fields:
    *   `prompt`: (String, Required) The user's input text for the chatbot.
    *   `temperature`: (Number, Optional) Controls the randomness of responses.  Higher values (e.g., 0.7 - 1) lead to more diverse and creative outputs, while lower values (e.g., 0.2 - 0.5) result in more predictable and focused responses. Defaults to 0.7.
    *   `max_tokens`: (Number, Optional) Limits the length of the generated response in tokens. Defaults to 250.
*   **Response Body (JSON):** Returns a JSON object containing:
    *   `response`: (String) The generated text response from the Gemma model.
    *   `model_version`: (String) The version of Google Gemma used.

**Example Request:**

```plaintext
  Write a short poem about autumn leaves.
```

**Example Response:**

```plaintext
  Crimson and gold, a vibrant hue,
  Falling leaves dance, kissed by the dew.
  A gentle breeze whispers through the trees,
  Autumn's beauty brings a sweet release.
```

## Setup and Running the Application

1.  **Install LM Studio:** Download and install LM Studio from [https://lmstudio.ai/](https://lmstudio.ai/).
2.  **Download Gemma 3-4b:** In LM Studio, search for and download the Google Gemma 3-4b model.
3.  **Build the Spring Boot Application:** Ensure you have a suitable IDE (e.g., IntelliJ, Eclipse) set up with the necessary Spring Boot dependencies in your project.
4.  **Run the Application:** Build and run your Spring Boot application. This will start the API server.

## Important Notes

*   **LM Studio Configuration:**  Make sure LM Studio is running and the Gemma 3-4b model is loaded before accessing the API.
*   **Resource Requirements:** Running Gemma 3-4b locally can require significant RAM and processing power.  Performance might vary depending on your system's hardware.
*   **API Key (Potentially):**  While the Gemma model itself does not require an API key, your Spring Boot application may need a Google Cloud account and the correct permissions set up to utilize the underlying Gemma API if needed for advanced features.

### This README.md content was generated using the very application you are reading about right now ðŸ˜‰.
```